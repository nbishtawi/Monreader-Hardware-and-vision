{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f60786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed\n",
    "from sklearn.metrics import f1_score\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25573182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image and model parameters\n",
    "image_width, image_height = 128, 128\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Define the image directories\n",
    "image_dir = 'C:/Users/User/Apviza/Project 4/images'\n",
    "training_dir = os.path.join(image_dir, 'training')\n",
    "testing_dir = os.path.join(image_dir, 'testing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f378ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image directories\n",
    "image_dir = 'C:/Users/User/Apviza/Project 4/images'\n",
    "training_dir = os.path.join(image_dir, 'training')\n",
    "testing_dir = os.path.join(image_dir, 'testing')\n",
    "\n",
    "\n",
    "# Load and preprocess the images\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(image_width, image_height))\n",
    "    img = img_to_array(img) / 255.0  # Normalize pixel values between 0 and 1\n",
    "    return img\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    flip_folder = os.path.join(folder, 'flip')\n",
    "    not_flip_folder = os.path.join(folder, 'notflip')\n",
    "\n",
    "    # Load images from the 'flip' folder\n",
    "    for filename in os.listdir(flip_folder):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            img = preprocess_image(os.path.join(flip_folder, filename))\n",
    "            images.append(img)\n",
    "            labels.append(1)  # Flipped page\n",
    "\n",
    "    # Load images from the 'notflip' folder\n",
    "    for filename in os.listdir(not_flip_folder):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            img = preprocess_image(os.path.join(not_flip_folder, filename))\n",
    "            images.append(img)\n",
    "            labels.append(0)  # Not flipped page\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b97b486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split the dataset\n",
    "X_train, y_train = load_images_from_folder(training_dir)\n",
    "X_test, y_test = load_images_from_folder(testing_dir)\n",
    "\n",
    "# Perform one-hot encoding on the labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Split training set into training and validation\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fix image size if necessary\n",
    "def fix_image_size(image):\n",
    "    return tf.image.resize(image, [image_width, image_height])\n",
    "\n",
    "X_train = fix_image_size(X_train)\n",
    "X_val = fix_image_size(X_val)\n",
    "X_test = fix_image_size(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25d2f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_metric(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4da1a3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 16s 246ms/step - loss: 0.6875 - accuracy: 0.5609 - f1_metric: 0.5632 - val_loss: 0.5985 - val_accuracy: 0.6764 - val_f1_metric: 0.6627\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 14s 240ms/step - loss: 0.4637 - accuracy: 0.7716 - f1_metric: 0.7738 - val_loss: 0.4361 - val_accuracy: 0.7975 - val_f1_metric: 0.7931\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 15s 248ms/step - loss: 0.2376 - accuracy: 0.8986 - f1_metric: 0.8974 - val_loss: 0.1635 - val_accuracy: 0.9499 - val_f1_metric: 0.9482\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 15s 249ms/step - loss: 0.1285 - accuracy: 0.9524 - f1_metric: 0.9532 - val_loss: 0.2062 - val_accuracy: 0.9269 - val_f1_metric: 0.9236\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 15s 250ms/step - loss: 0.1197 - accuracy: 0.9556 - f1_metric: 0.9525 - val_loss: 0.3075 - val_accuracy: 0.8685 - val_f1_metric: 0.8718\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 15s 242ms/step - loss: 0.0845 - accuracy: 0.9692 - f1_metric: 0.9682 - val_loss: 0.0786 - val_accuracy: 0.9791 - val_f1_metric: 0.9792\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 17s 280ms/step - loss: 0.0553 - accuracy: 0.9827 - f1_metric: 0.9834 - val_loss: 0.0808 - val_accuracy: 0.9729 - val_f1_metric: 0.9729\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 16s 263ms/step - loss: 0.0291 - accuracy: 0.9927 - f1_metric: 0.9909 - val_loss: 0.0550 - val_accuracy: 0.9875 - val_f1_metric: 0.9875\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 15s 252ms/step - loss: 0.0231 - accuracy: 0.9922 - f1_metric: 0.9922 - val_loss: 0.0331 - val_accuracy: 0.9833 - val_f1_metric: 0.9843\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 16s 269ms/step - loss: 0.0402 - accuracy: 0.9854 - f1_metric: 0.9857 - val_loss: 0.0549 - val_accuracy: 0.9833 - val_f1_metric: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16df3e99c70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\",f1_metric])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eef936db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 52ms/step\n",
      "F1 Score: 0.964765100671141\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4e86ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image directories\n",
    "image_dir = 'C:/Users/User/Apviza/Project 4/images'\n",
    "training_dir = os.path.join(image_dir, 'training')\n",
    "testing_dir = os.path.join(image_dir, 'testing')\n",
    "\n",
    "# Parameters\n",
    "image_width = 64\n",
    "image_height = 64\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "\n",
    "# Load and preprocess the images\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(image_width, image_height))\n",
    "    img = img_to_array(img) / 255.0  # Normalize pixel values between 0 and 1\n",
    "    return img\n",
    "\n",
    "def load_sequences_from_folder(folder):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    flip_folder = os.path.join(folder, 'flip')\n",
    "    not_flip_folder = os.path.join(folder, 'notflip')\n",
    "\n",
    "    # Load sequences from the 'flip' folder\n",
    "    for filename in sorted(os.listdir(flip_folder)):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(flip_folder, filename)\n",
    "            sequence_id = filename.split('_')[0]\n",
    "            frame_number = filename.split('_')[1].split('.')[0]\n",
    "            sequence = sequences[-1][1] if sequences else []\n",
    "            sequence.append((frame_number, preprocess_image(image_path)))\n",
    "            if not sequences or sequence_id != sequences[-1][0]:\n",
    "                sequences.append((sequence_id, sequence))\n",
    "\n",
    "    # Load sequences from the 'notflip' folder\n",
    "    for filename in sorted(os.listdir(not_flip_folder)):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(not_flip_folder, filename)\n",
    "            sequence_id = filename.split('_')[0]\n",
    "            frame_number = filename.split('_')[1].split('.')[0]\n",
    "            sequence = sequences[-1][1] if sequences else []\n",
    "            sequence.append((frame_number, preprocess_image(image_path)))\n",
    "            if not sequences or sequence_id != sequences[-1][0]:\n",
    "                sequences.append((sequence_id, sequence))\n",
    "\n",
    "    # Sort the frames within each sequence by frame number\n",
    "    for _, sequence in sequences:\n",
    "        sequence.sort(key=lambda x: int(x[0]))\n",
    "\n",
    "    # Create labels based on the presence of 'flip' or 'notflip' folder\n",
    "    for sequence in sequences:\n",
    "        if os.path.exists(os.path.join(flip_folder, f\"{sequence[1][0][0]}.jpg\")):\n",
    "            labels.append(1)  # Flipped page\n",
    "        else:\n",
    "            labels.append(0)  # Not flipped page\n",
    "\n",
    "    return sequences, np.array(labels)\n",
    "\n",
    "# Define the data generator for training\n",
    "def data_generator(sequences, labels, batch_size):\n",
    "    num_batches = len(sequences) // batch_size\n",
    "    while True:\n",
    "        for i in range(num_batches):\n",
    "            batch_sequences = sequences[i*batch_size:(i+1)*batch_size]\n",
    "            batch_labels = labels[i*batch_size:(i+1)*batch_size]\n",
    "            train_sequences_processed = np.array([np.array([frame[1] for frame in sequence]) for _, sequence in batch_sequences])\n",
    "            train_labels_processed = batch_labels\n",
    "            yield train_sequences_processed, train_labels_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "879ae30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training sequences and labels\n",
    "train_sequences, train_labels = load_sequences_from_folder(training_dir)\n",
    "\n",
    "# Load testing sequences and labels\n",
    "test_sequences, test_labels = load_sequences_from_folder(testing_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "beca7a63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Design the RNN model architecture\n",
    "sq_model = tf.keras.Sequential()\n",
    "sq_model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu'), input_shape=(None, image_width, image_height, 3)))\n",
    "sq_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "sq_model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "sq_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "sq_model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\n",
    "sq_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "sq_model.add(TimeDistributed(Flatten()))\n",
    "sq_model.add(LSTM(32, return_sequences=True))\n",
    "sq_model.add(LSTM(32))\n",
    "sq_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "sq_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11983fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 350s 3s/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 349s 3s/step - loss: 9.0966e-04 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 348s 3s/step - loss: 5.7137e-04 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 338s 3s/step - loss: 4.0497e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 351s 3s/step - loss: 3.0688e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 350s 3s/step - loss: 2.4215e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 349s 3s/step - loss: 1.9661e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 349s 3s/step - loss: 1.6307e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 348s 3s/step - loss: 1.3752e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 350s 3s/step - loss: 1.1755e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Create the data generator\n",
    "train_data_generator = data_generator(train_sequences, train_labels, batch_size)\n",
    "\n",
    "# Train the model using the data generator\n",
    "steps_per_epoch = len(train_sequences) // batch_size\n",
    "#sq_model.fit(train_data_generator, steps_per_epoch=steps_per_epoch, epochs=epochs)\n",
    "sq_model.fit(train_data_generator, steps_per_epoch=steps_per_epoch, epochs=epochs)\n",
    "\n",
    "# Preprocess testing sequences\n",
    "test_sequences_processed = np.array([np.array([frame[1] for frame in sequence]) for _, sequence in test_sequences])\n",
    "test_labels_processed = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c451904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 26s 6s/step\n",
      "Test Loss: 0.00010893327998928726\n",
      "Test Accuracy: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = sq_model.evaluate(test_sequences_processed, test_labels, verbose=0)\n",
    "predictions = sq_model.predict(test_sequences_processed)\n",
    "f1score = f1_score(test_labels, predictions.round(), zero_division=1)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "print('F1 Score:', f1score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
